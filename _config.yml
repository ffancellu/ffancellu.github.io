exclude: ['README.md']
timezone: US/Eastern
papers:
  - layout: paper
    paper-type: inproceedings
    selected: yes
    year: 2017
    img: monokuma
    title: "Edina: Building an Open Domain Socialbot with Self-dialogues"
    authors: Ben Krause, Marco Damonte, Mihai Dobre, Daniel Duma, Joachim Fainberg,
    Federico Fancellu, Emmanuel Kahembwe, Jianpeng Cheng, Bonnie Webber
    booktitle: ArXiv
    booktitle-url: https://arxiv.org/abs/1709.09816
    doc-url: https://arxiv.org/abs/1709.09816
    abstract: >
        We present Edina, the University of Edinburgh's social bot for the Amazon
        Alexa Prize competition. Edina is a conversational agent whose responses
        utilize data harvested from Amazon Mechanical Turk (AMT) through an
        innovative new technique we call self-dialogues. These are conversations
        in which a single AMT Worker plays both participants in a dialogue. Such
        dialogues are surprisingly natural, efficient to collect and reflective
        of relevant and/or trending topics. These self-dialogues provide training
        data for a generative neural network as well as a basis for soft rules
        used by a matching score component. Each match of a soft rule against a
        user utterance is associated with a confidence score which we show is
        strongly indicative of reply quality, allowing this component to self-censor
        and be effectively integrated with other components. Edina's full architecture
        features a rule-based system backing off to a matching score, backing off
        to a generative neural network. Our hybrid data-driven methodology thus
        addresses both coverage limitations of a strictly rule-based approach and
        the lack of guarantees of a strictly machine-learning approach
  - layout: paper
    paper-type: inproceedings
    selected: yes
    year: 2017
    img: monokuma
    title: "Universal Dependencies to Logical Forms with Negation Scope"
    authors: Federico Fancellu, Siva Reddy, Adam Lopez and Bonnie Webber
    booktitle: ArXiv (To appear in the Proceeding of the SemBEAR workshop)
    booktitle-url: http://www.cse.unt.edu/sembear2017/
    doc-url: https://arxiv.org/pdf/1702.03305.pdf
    venue: workshop
    abstract: >
        Many language technology applications would benefit from the ability to represent
        negation and its scope on top of widely-used linguistic resources. In this paper, we
        investigate the possibility of obtaining a first-order logic representation
        with negation scope marked using Universal Dependencies. To do so, we enhance
        UDepLambda, a framework that converts dependency graphs to logical forms.
        The resulting UDepLambda¬ is able to handle phenomena related to scope by means of
        an higher-order type theory, relevant not only to negation but also to universal
        quantification and other complex semantic phenomena. The initial conversion we did for
        English is promising, in that one can represent the scope of negation also
        in the presence of more complex phenomena such as universal quantifiers.
  - layout: paper
    paper-type: inproceedings
    selected: yes
    year: 2017
    img: monokuma
    title: "Neural Networks for Negation Cue Detection in Chinese"
    authors: Hangfeng He, Federico Fancellu, Bonnie Webber
    booktitle: Proceedings of SemBEAR workshop@EACL2017
    booktitle-url: http://www.cse.unt.edu/sembear2017/
    venue: conference
    abstract: >
      Negation cue detection involves identifying  the  span  inherently
      expressing  negation  in  a  negative  sentence.   In  Chinese,
      negative  cue  detection  is  complicated  by morphological proprieties
      of the language. Previous  work  has  shown  that  negative cue detection
      in Chinese can benefit from specific  lexical  and  morphemic  features,
      as well as cross-lingual information. We show here that they are not
      necessary:  A bi-directional LSTM can perform equally well,  with  minimal
      feature  engineering. In particular, the use of a character-based
      model allows us to capture characteristics of  negation  cues  in  Chinese
      using  word-embedding  information  only. Not  only does our model
      performs on par with previous work, further error analysis clarifies
      what problems remain to be addressed.
  - layout: paper
    paper-type: inproceedings
    selected: yes
    year: 2017
    img: monokuma
    title: "Detecting negation scope is easy, except when it isn't"
    authors: Federico Fancellu, Adam Lopez, and Bonnie Webber and Hangfeng He
    booktitle: Proceedings of EACL
    booktitle-url: http://eacl2017.org/
    venue: conference
    abstract: >
      Several corpora have been annotated with negation scope - the set of words
      whose meaning is negated by a cue like the word ``not'' - leading to the
      development of classifiers that detect negation scope with high accuracy.
      We show that for nearly all of these corpora, this high accuracy can be
      attributed to a single fact:  they frequently annotate negation scope as
      a single span of text delimited by punctuation. For negation scopes not
      of this form, detection accuracy is low and under-sampling the easy
      training examples does not substantially improve accuracy. We demonstrate
      that this is partly an artifact of annotation guidelines, and we
      argue that future negation scope annotation efforts should focus on these
      more difficult cases.
  - layout: paper
    paper-type: inproceedings
    selected: yes
    year: 2016
    img: monokuma
    title: "Neural networks for negation scope detection"
    authors: Federico Fancellu, Adam Lopez, and Bonnie Webber
    booktitle: Proceedings of ACL
    code: https://github.com/ffancellu/NegNN
    booktitle-url: http://acl2016.org/
    doc-url: https://drive.google.com/file/d/0B7cpo43vOGF1Umw0dHNtQXZiMGs/view
    venue: conference
    abstract: >
      Automatic negation scope detection is a task that has been tackled
      using different classifiers and heuristics. Most systems are however
      1) highly-engineered, 2) English-specific, and 3) only tested on
      the same genre they were trained on. We start by addressing 1) and 2)
      using a neural network architecture. Results obtained on data from
      the *SEM2012 shared task on negation scope detection show that even a
      simple feed-forward neural network using word-embedding features
      alone, performs on par with earlier classifiers, with a
      bi-directional LSTM outperforming all of them. We then address 3) by
      means of a specially-designed synthetic test set; in doing so, we
      explore the problem of detecting the negation scope more in depth and
      show that performance suffers from genre effects and differs with the
      type of negation considered.
  - layout: paper
    paper-type: inproceedings
    selected: yes
    year: 2015
    img: monokuma
    title: "Translating negation: A Manual Eror Analysis"
    authors: Federico Fancellu and Bonnie Webber
    booktitle: Proceedings of Ex-Prom 2015 (Extra-Propositional Aspects of Meaning in Computational Linguistics) workshop
    booktitle-url: http://www.cse.unt.edu/exprom2015/
    doc-url: http://www.aclweb.org/anthology/W15-1301
    venue: conference
    abstract: >
        Statistical Machine Translation has come a long way improving
        the  translation  quality ofa  range  of  different  linguistic
        phenomena.  With negation however, techniques proposed and implemented
        for improving translation performance on negation have simply followed
        from the developers’ beliefs about why performance is worse.
        These beliefs, however, have never been validated by an error analysis
        of the translation output.  In contrast, the current paper shows that an
        informative empirical error analysis can be formulated in terms of (1)
        the  set  of  semantic  elements  involved in  the  meaning  of
        negation,  and  (2)  a  small set of  string-based  operations  that
        can characterise errors in the translation of those elements.
        Results on a Chinese-to-English translation task confirm the robustness
        of our analysis cross-linguistically and the basic assumptions can
        inform  an  automated  investigation into the causes of translation
        errors. Conclusions  drawn  from  this  analysis  should  guide future
        work  on  improving  the  translation of negative sentences.
  - layout: paper
    paper-type: inproceedings
    selected: yes
    year: 2014
    img: monokuma
    title: "Applying the semantics of negation to SMT through n-best list re-ranking"
    authors: Federico Fancellu and Bonnie Webber
    booktitle: Proceedings of EACL
    booktitle-url: http://eacl2014.org/
    doc-url: http://www.aclweb.org/anthology/E14-1063
    venue: conference
    abstract: >
      Although the performance of SMT systems has improved over a range of different
      linguistic phenomena, negation has not yet received adequate treatment. Previous
      works have considered the problem of translating negative data as one of data sparsity
      (Wetzel and Bond (2012)) or of structural differences between source and target language
      with respect to the placement of negation (Collins et al. (2005)). This work starts
      instead from the questions of what is meant by negation and what makes a good
      translation of negation. These questions have led us to explore the use of
      semantics of negation in SMT — specifically, identifying core semantic elements
      of negation (cue, event and scope) in a source-side dependency parse and reranking
      hypotheses on the n-best list produced after decoding according to the extent to
      which an hypothesis realises these elements. The method shows considerable
      improvement over the baseline as measured by BLEU scores and Stanford’s
      entailment-based MT evaluation metric (Padó et al. (2009)).
